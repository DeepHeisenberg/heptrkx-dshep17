{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "#os.environ.pop('CUDA_VISIBLE_DEVICES')\n",
    "#os.unsetenv('CUDA_VISIBLE_DEVICES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "import itertools\n",
    "import glob\n",
    "\n",
    "# Package imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import models, layers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Local imports\n",
    "#import dutils\n",
    "#import drawing\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(2341)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "hits_row_names = [\"event_id\", \"track_id\", \"i_r\", \"i_phi\", \"x\", \"y\"]\n",
    "particles_row_names = [\"event_id\", \"p_id\", \"pt\", \"phi\", \"vx\", \"vy\"]\n",
    "n_r_bins = 9\n",
    "n_phi_bins = 1000\n",
    "max_tracks = 25\n",
    "pt_scale = 2*np.pi/20000 # for loss function\n",
    "\n",
    "def get_phi(x, y):\n",
    "    return np.arctan2(y, x)\n",
    "\n",
    "def discretize(evt, phiwidth):\n",
    "    \"\"\"\n",
    "    evt: pandas dataframe holding hit information for one event\n",
    "    phiwidth: size of pixel in phi direction\n",
    "    \n",
    "    Converts the hit information in the event into a numpy array with\n",
    "    hits represented by 1's.\n",
    "    \"\"\"\n",
    "    \n",
    "    r_grid = np.arange(n_r_bins)\n",
    "    phi_grid = np.arange(0., 2*np.pi, phiwidth)\n",
    "    image = np.zeros((1, len(r_grid),len(phi_grid)))\n",
    "    try:\n",
    "        for hit in evt.itertuples():\n",
    "            ir = hit[hits_row_names.index('i_r')]\n",
    "            x = hit[hits_row_names.index('x')]\n",
    "            y = hit[hits_row_names.index('y')]\n",
    "            phi = get_phi(x, y)\n",
    "            iphi = int((phi/phiwidth))\n",
    "            image[0,ir,iphi] = 1\n",
    "    except AttributeError:\n",
    "        # This occurs if the event has only one hit (rare), in which case evt\n",
    "        # is a Series, not a DataFrame.  Deal with this separately.\n",
    "        print \"Encountered event with only one hit:\",evt\n",
    "        \n",
    "    return image\n",
    "\n",
    "def get_targets(evt, max_tracks):\n",
    "    \"\"\"\n",
    "    evt: pandas dataframe holding particle info for one event\n",
    "    \n",
    "    Gets the pt and phi of each particle in the event and returns them in a numpy array,\n",
    "    scaled to an appropriate scale.\n",
    "    \"\"\"\n",
    "    particles = np.zeros((max_tracks, 2))\n",
    "    weights = np.zeros(max_tracks)\n",
    "    try:\n",
    "        for i,particle in enumerate(evt.itertuples()):\n",
    "            if i >= max_tracks:\n",
    "                break\n",
    "            particles[i, 0] = particle[particles_row_names.index('pt')]*pt_scale\n",
    "            particles[i, 1] = particle[particles_row_names.index('phi')]\n",
    "            weights[i] = 1\n",
    "        particles[:i+1] = particles[particles[:i+1,1].argsort()] # sort by second column (phi)\n",
    "    except AttributeError:\n",
    "        # This occurs if the event has only one particle, in which case evt is\n",
    "        # a Series, not a DataFrame.  Deal with this separately.\n",
    "        particles[0, 0] = evt['pt']*pt_scale\n",
    "        particles[0, 1] = evt['phi']\n",
    "        weights[0] = 1\n",
    "    \n",
    "    return particles, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def gen_single_hits(hit_files):\n",
    "    cur_file = 0\n",
    "    num_files = len(hit_files)\n",
    "    while True:\n",
    "        df = pd.read_csv(hit_files[cur_file], header=None, names=hits_row_names, index_col=hits_row_names[0])\n",
    "        event_nums = sorted(df.index.unique())\n",
    "        for event_num in event_nums:\n",
    "            yield discretize(df.loc[event_num], phiwidth=2*np.pi/n_phi_bins)\n",
    "        cur_file += 1\n",
    "        if cur_file >= num_files:\n",
    "            cur_file = 0\n",
    "\n",
    "def gen_single_particles(particle_files, max_tracks):\n",
    "    cur_file = 0\n",
    "    num_files = len(particle_files)\n",
    "    while True:\n",
    "        df = pd.read_csv(particle_files[cur_file], header=None, names=particles_row_names, index_col=particles_row_names[0])\n",
    "        event_nums = sorted(df.index.unique())\n",
    "        for event_num in event_nums:\n",
    "            yield get_targets(df.loc[event_num], max_tracks)\n",
    "        cur_file += 1\n",
    "        if cur_file >= num_files:\n",
    "            cur_file = 0\n",
    "    \n",
    "def generate_data(batch_size, hit_files, particle_files, max_tracks=max_tracks):\n",
    "    gen_hits = gen_single_hits(hit_files)\n",
    "    gen_particles = gen_single_particles(particle_files, max_tracks)\n",
    "    while True:\n",
    "        batch_events = np.array([evt for evt in itertools.islice(gen_hits, batch_size)])\n",
    "        batch_targets = np.zeros((batch_size, max_tracks, 2))\n",
    "        batch_weights = np.zeros((batch_size, max_tracks))\n",
    "        for i,(particles, weights) in enumerate(itertools.islice(gen_particles, batch_size)):\n",
    "            batch_targets[i] = particles\n",
    "            batch_weights[i] = weights\n",
    "        yield batch_events, batch_targets, batch_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "hit_files = sorted(glob.glob(\"/inputdata/hits_*.csv\"))\n",
    "particle_files = sorted(glob.glob(\"/inputdata/particles_*.csv\"))\n",
    "generator = generate_data(256, hit_files, particle_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/bigdata/shared/TkRamp/hits_1000_3500.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3501.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3502.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3503.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3504.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3505.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3506.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3507.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3508.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3509.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3510.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3511.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3512.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3513.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3514.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3515.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3516.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3517.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3518.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3519.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3520.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3521.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3522.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3523.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3524.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3525.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3526.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3527.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3528.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3529.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3530.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3531.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3532.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3533.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3534.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3535.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3536.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3537.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3538.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3539.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3540.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3541.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3542.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3543.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3544.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3545.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3546.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3547.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3548.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3549.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3550.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3551.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3552.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3553.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3554.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3555.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3556.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3557.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3558.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3559.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3560.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3561.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3562.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3563.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3564.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3565.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3566.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3567.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3568.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3569.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3570.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3571.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3572.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3573.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3574.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3575.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3576.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3577.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3578.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3579.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3580.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3581.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3582.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3583.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3584.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3585.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3586.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3587.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3588.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3589.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3590.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3591.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3592.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3593.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3594.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3595.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3596.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3597.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3598.csv',\n",
       " '/bigdata/shared/TkRamp/hits_1000_3599.csv']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "def build_model_1(max_tracks=max_tracks):\n",
    "    internal = 150\n",
    "    input_layer = layers.Input(shape=(1, n_r_bins, n_phi_bins))\n",
    "    \n",
    "    layer1 = layers.Convolution2D(8, 2, 6, border_mode='same')(input_layer)\n",
    "    layer1 = layers.Activation('relu')(layer1)\n",
    "    layer1 = layers.Convolution2D(8, 2, 6, border_mode='same')(layer1)\n",
    "    layer1 = layers.Activation('relu')(layer1)\n",
    "    layer1 = layers.MaxPooling2D(pool_size=(1,4))(layer1)\n",
    "    layer1 = layers.Convolution2D(16, 2, 6, border_mode='same')(layer1)\n",
    "    layer1 = layers.Activation('relu')(layer1)\n",
    "    layer1 = layers.Convolution2D(16, 2, 6, border_mode='same')(layer1)\n",
    "    layer1 = layers.Activation('relu')(layer1)\n",
    "    layer1 = layers.Flatten()(layer1)\n",
    "    \n",
    "    layer2 = layers.Convolution2D(8, 2, 12, border_mode='same')(input_layer)\n",
    "    layer2 = layers.Activation('relu')(layer2)\n",
    "    layer2 = layers.Convolution2D(8, 2, 12, border_mode='same')(layer2)\n",
    "    layer2 = layers.Activation('relu')(layer2)\n",
    "    layer2 = layers.MaxPooling2D(pool_size=(2,4))(layer2)\n",
    "    layer2 = layers.Convolution2D(16, 2, 6, border_mode='same')(layer2)\n",
    "    layer2 = layers.Activation('relu')(layer2)\n",
    "    layer2 = layers.Convolution2D(16, 2, 6, border_mode='same')(layer2)\n",
    "    layer2 = layers.Activation('relu')(layer2)\n",
    "    layer2 = layers.Flatten()(layer2)\n",
    "    \n",
    "    layer3 = layers.Convolution2D(8, 4, 12, border_mode='same')(input_layer)\n",
    "    layer3 = layers.Activation('relu')(layer3)\n",
    "    layer3 = layers.Convolution2D(8, 4, 12, border_mode='same')(layer3)\n",
    "    layer3 = layers.Activation('relu')(layer3)\n",
    "    layer3 = layers.Flatten()(layer3)\n",
    "    \n",
    "    layer = layers.merge([layer1, layer2, layer3], mode='concat', concat_axis=1)\n",
    "    layer = layers.Dense(internal)(layer)\n",
    "    layer = layers.RepeatVector(max_tracks)(layer)\n",
    "    layer = layers.LSTM(internal, return_sequences=True)(layer)\n",
    "    output_layer = layers.TimeDistributed(layers.Dense(2))(layer)\n",
    "    model = models.Model(input=input_layer, output=output_layer)\n",
    "    model.compile(loss='mean_squared_error', optimizer='Adam', sample_weight_mode=\"temporal\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_1 = build_model_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 1, 9, 1000)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D) (None, 8, 9, 1000)    104         input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_15 (Convolution2D) (None, 8, 9, 1000)    200         input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, 8, 9, 1000)    0           convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_15 (Activation)       (None, 8, 9, 1000)    0           convolution2d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 8, 9, 1000)    776         activation_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_16 (Convolution2D) (None, 8, 9, 1000)    1544        activation_15[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 8, 9, 1000)    0           convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_16 (Activation)       (None, 8, 9, 1000)    0           convolution2d_16[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 8, 9, 250)     0           activation_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 8, 4, 250)     0           activation_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_13 (Convolution2D) (None, 16, 9, 250)    1552        maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_17 (Convolution2D) (None, 16, 4, 250)    1552        maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_19 (Convolution2D) (None, 8, 9, 1000)    392         input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, 16, 9, 250)    0           convolution2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_17 (Activation)       (None, 16, 4, 250)    0           convolution2d_17[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_19 (Activation)       (None, 8, 9, 1000)    0           convolution2d_19[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_14 (Convolution2D) (None, 16, 9, 250)    3088        activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_18 (Convolution2D) (None, 16, 4, 250)    3088        activation_17[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_20 (Convolution2D) (None, 8, 9, 1000)    3080        activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)       (None, 16, 9, 250)    0           convolution2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_18 (Activation)       (None, 16, 4, 250)    0           convolution2d_18[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_20 (Activation)       (None, 8, 9, 1000)    0           convolution2d_20[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)              (None, 36000)         0           activation_14[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)              (None, 16000)         0           activation_18[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)              (None, 72000)         0           activation_20[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "merge_2 (Merge)                  (None, 124000)        0           flatten_4[0][0]                  \n",
      "                                                                   flatten_5[0][0]                  \n",
      "                                                                   flatten_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 150)           18600150    merge_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "repeatvector_2 (RepeatVector)    (None, 25, 150)       0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    (None, 25, 150)       180600      repeatvector_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_2 (TimeDistribut (None, 25, 2)         302         lstm_2[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 18,796,428\n",
      "Trainable params: 18,796,428\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 7168/96000 [=>............................] - ETA: 384s - loss: 2.4111"
     ]
    }
   ],
   "source": [
    "%time model_1.fit_generator(generator, samples_per_epoch=96000, nb_epoch=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%time model_1.fit_generator(generator, samples_per_epoch=96000, nb_epoch=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "evt, truth, weight = generator.next()\n",
    "#pred = model_1.predict(np.array([evt[0]]))\n",
    "pred = model_1.predict(evt)\n",
    "print \"Model prediction\"\n",
    "print pred[0]\n",
    "print \"Target\"\n",
    "print truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "diff = []\n",
    "relative_diff = []\n",
    "for i in range( truth.shape[0]):\n",
    "    t = truth[i]\n",
    "    p = pred[i]\n",
    "    one = np.where(t[:,0] !=0 )\n",
    "    #print t[one,0]\n",
    "    #print p[one,0]\n",
    "    d  = (t[one,0] - p[one,0])\n",
    "    rd = d /t[one,0] \n",
    "    diff.extend(d.ravel())\n",
    "    relative_diff.extend(rd.ravel())\n",
    "\n",
    "\n",
    "plt.hist(diff )\n",
    "plt.xlabel('truth-prediction')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(relative_diff )\n",
    "plt.xlabel('truth-prediction/prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
